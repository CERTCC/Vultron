# Implementation Notes

Longer-term notes can be found in `/notes/*.md`. This file is ephemeral
and will be reset periodically, so it's meant to capture more immediate
insights, issues, and learnings during the implementation process.

Add new items below this line

## BUG FIX — mkdocs serve ImportError from griffe (2026-02-26)

**Issue**: `uv run mkdocs serve` (and `mkdocs build`) failed with
`ImportError: cannot import name 'Alias' from 'griffe' (unknown location)`.

**Root cause**: `pyproject.toml` listed three griffe-related packages as
direct dependencies: `griffe>=2.0.0` (a CLI stub), `griffelib>=2.0.0` (the
real griffe library), and `griffecli>=2.0.0` (the CLI). The stub `griffe`
2.0.0 package and `griffelib` 2.0.0 both contribute to the `griffe` Python
namespace. When uv installs them together, `griffelib`'s `griffe/__init__.py`
and most of its source files were absent from the venv, leaving `griffe` as
an empty namespace package. `mkdocstrings-python` then failed to import
`Alias` from it.

**Fix**: Removed `griffe>=2.0.0` and `griffecli>=2.0.0` from `pyproject.toml`.
`griffelib>=2.0.0` alone provides the full `griffe` Python module (and is also
a direct dependency of `mkdocstrings-python`).

---



**Issue**: `test_check_server_availability_logs_retry_attempts` passed in
isolation but failed when the full test suite ran.

**Root cause**: `check_server_availability` logs at `DEBUG` level.
`TestCliLogging` tests in `test/demo/test_cli.py` invoke the Vultron demo
CLI, which calls `logging.basicConfig(level=INFO, force=True)`. This raises
the root logger's effective level to INFO, suppressing DEBUG messages.
`TestCliLogging.teardown_method` reset root to `WARNING`, which compounded the
problem. `TestCliSubCommands` and `TestCliAll` also invoke the CLI (without a
matching teardown), leaving root at INFO after the last `test_cli.py` test.
When `test_check_server_availability_logs_retry_attempts` then ran, root was
at INFO, `caplog` captured nothing, and the assertion failed.

**Fix**:
1. `test/scripts/test_health_check_retry.py`: Wrapped the call and assertion
   inside `with caplog.at_level(logging.DEBUG):` — the test now explicitly
   declares the log level it requires, making it independent of external
   logger state.
2. `test/demo/test_cli.py`: Changed `teardown_method` to restore root logger
   to `logging.NOTSET` (unconditional pass-through) instead of `WARNING`,
   reducing interference with subsequent tests.

**Note on `vultron/api/v2/app.py`**: This module sets the root logger to
DEBUG at import time (`logging.getLogger().setLevel(logging.DEBUG)`). This
side-effect is the reason the test passed in isolation — importing demo
modules pulls in `app.py`, which sets root to DEBUG before the test runs.
This module-level side-effect on the root logger is a separate concern and
should be addressed in a future cleanup.

## BUG FIX — Demo CLI logging (2026-02-26)

`vultron-demo` sub-commands produced no console output because the `main`
click group never configured a logging handler. Python's default root logger
level is WARNING, silently discarding all INFO-level demo messages.

**Fix**: Added `--debug` and `--log-file` options to the `main` group; the
group callback now calls `logging.basicConfig(force=True)` at INFO (or DEBUG
with `--debug`). Tests covering the new behaviour are in
`test/demo/test_cli.py`.


## Outbox Delivery Gap

`vultron/api/v2/data/actor_io.py` has a placeholder that appends strings to an
outbox list but does not write to any recipient actor's inbox. No delivery
mechanism exists. This means outbox-based activities (e.g., CreateCase
activity generated by `create_case` handler) are never actually received by
other actors. This is acceptable for the prototype demos (which sequence
activities manually) but must be resolved before the `CaseActor` broadcast
model (Priority 200) can work correctly.

## CM-03-006 Rename Risk

`VulnerabilityCase.case_status` (list field with singular name) is referenced
throughout `handlers.py` (~20 call sites), `behaviors/`, and many tests.
The rename to `case_statuses` is a correctness improvement per the spec but
carries significant breakage risk. Run `grep -rn "\.case_status" vultron/ test/`
before starting to quantify scope. Consider doing `case_statuses` and
`participant_statuses` renames in the same PR to keep the diff localized.

## DEMO-4 Isolation Complexity

When running multiple demos in sequence (via the `all` sub-command), each demo
must leave the DataLayer in a clean state. The current demo scripts were each
designed to run against a clean slate. Key risks:

- Demos that create actors with fixed IDs (e.g., `vendor`, `finder`) will
  conflict on second run unless teardown deletes those actors.
- The `manage_case_demo` and `manage_embargo_demo` share similar object types;
  ensure teardown is comprehensive.
- Teardown should use the DataLayer directly (not via HTTP inbox) to guarantee
  cleanup even when the demo fails mid-way.

Consider designing a demo context manager that can be used as a `with` block
around each demo. The `__enter__` method can set up tracking to record the IDs of 
all created DataLayer entries, and the `__exit__` method can iterate those IDs and delete 
them from the DataLayer to ensure a clean slate for the next demo. 
This would also help ensure that teardown runs even if the demo encounters an 
error, as the `__exit__` method of a context manager is guaranteed to execute 
regardless of exceptions.

More generally: given the choice between implementing identical 
try/except/finally clean up logic when it will be repeated across multiple 
locations, versus implementing a reusable context manager that abstracts 
that logic, the context manager is likely the better choice for 
maintainability and reducing code duplication.

## DEMO-4 Docker Interaction Mode

The unified demo container should be interactive by default (`docker compose
run demo` or `docker compose up demo` with TTY). The `DEMO` env var override
(`DEMO=receive-report docker compose up demo`) is the non-interactive path for
CI or scripted runs. Verify that click's interactive prompts degrade gracefully
when stdin is not a TTY (use `click.echo` + non-interactive fallback if needed).

Also ensure that the startup process (presumably in `docker-compose.yml`?) demo 
container has appropriate dependency on the `api-dev` container so that 
running the demo container will also trigger the API container to start if 
it's not already running, and that the demo container waits for the API to 
be available before starting the demo script. This will help ensure a 
smoother  experience for users who may not have the API container already running.
We want this to be as turnkey as possible, so minimizing manual steps for demo
users is a key goal.

## DEMO-4.4 Isolation Implementation (2026-02-26)

Added `demo_environment(client)` context manager to `vultron/demo/utils.py`.
It calls `setup_clean_environment()` on entry and `reset_datalayer(init=False)` +
`clear_all_actor_ios()` in a `finally` block on exit. All 12 demo scripts updated
to use `with demo_environment(client) as (finder, vendor, coordinator):` in their
`main()` loops, replacing the bare `setup_clean_environment()` call. This satisfies
DC-03-001 (teardown runs even on exception) and DC-03-003 (each invocation manages
its own context).

## DEMO-4.11 Resolved (2026-02-26)

`DEFAULT_WAIT_SECONDS = 1.0` added to `vultron/demo/utils.py`.
`post_to_inbox_and_wait` now reads this constant when `wait_seconds` is not
explicitly provided. `test/demo/conftest.py` sets it to `0.0` at import time,
eliminating all `time.sleep` calls in the test environment. A `make_testclient_call`
factory in `test/demo/_helpers.py` replaces the 30-line closure duplicated across
all 12 demo test files. The shared `client` fixture in conftest removes 12 redundant
fixture definitions. Demo suite runtime dropped from ~4 minutes to ~28 seconds.

## DEMO-4.3 Complete (2026-02-26)

All 12 `*_demo.py` scripts moved from `vultron/scripts/` to `vultron/demo/`.
Updated all test imports in `test/scripts/` (`from vultron.scripts import X_demo`
→ `from vultron.demo import X_demo`). Updated Dockerfile CMDs to use
`vultron.demo.X_demo`. 568 tests pass.

`vultron/demo/utils.py` created with all shared utilities extracted from
`initialize_case_demo.py`: `demo_step`, `demo_check`, `logfmt`, `postfmt`,
`BASE_URL`, `DataLayerClient`, `reset_datalayer`, `discover_actors`,
`init_actor_ios`, `post_to_inbox_and_wait`, `verify_object_stored`,
`get_offer_from_datalayer`, `log_case_state`, `setup_clean_environment`,
`check_server_availability`.

`initialize_case_demo.py` updated to import from `vultron.demo.utils`. All
other demo scripts continue to import via `initialize_case_demo` (DEMO-4.2
will update them to import directly from `vultron.demo.utils`).
568 tests pass.

## Documentation needed

1. `vultron/demo/README.md` should contain a high-level 
   overview of the 
   demo 
   suite, instructions for running the demos via docker-compose and directly,
   along with any prerequisites or setup steps needed.
2. The workflow descriptions in `docs/howto/activitypub/activities/*.md` 
   should be expanded to include references to the relevant demo scripts, 
   possibly via example or tip admonitions that point readers to the demos 
   for concrete examples of the workflows in action. Docker-compose instructions
   can be included in examples on each page. If this ends up being a lot of 
   duplication, consider creating a single admonition file in 
   `docs/includes/` to be included on each page that needs it. See examples 
   of existing admonitions in `docs/includes/` for reference.
3. TUTORIAL-1: A tutorial in `docs/tutorials/` that walks through the 
   process of 
   setting 
   up for running the `receive-report` demo in a local environment via 
   docker-compose. Tutorials can provide links to other docs for deeper 
   dives, but they should be entirely self-contained with respect to the 
   learning goals of the individual tutorial.
4. TUTORIAL-2: A second tutorial that follows item 3 but tells users how to run 
   the 
   other demos and what they show. It can assume TUTORIAL-1 as a 
   prerequisite and focus on what users will learn from the other demos. 
5. Reference documentation for the demo utilities and demos themselves 
   belongs in `docs/reference/code/demo/*.md` as a new section for the demo 
   suite. Each utility function should have a docstring with a description of its 
   purpose, parameters, and return value. The demo scripts themselves should 
   also have docstrings at the module level describing their purpose and any
   important details about their implementation.

NOTE: For updates in the `docs/` directory, be sure to study 
`notes/diataxis-framework.md` to understand our documentation strategy, and 
`specs/diataxis-requirements.md` for specific documentation requirements.

NOTE 2: Be sure to update `mkdocs.yml` to include any new or moved files in 
`docs/`

## Docker builds are slow

The process for building the `demo` and `api-dev` docker images is currently 
taking multiple minutes. There are definitely optimizations that can be made 
either to the `docker/Dockerfile` or to the `docker/docker-compose.yml` to speed 
this up. 

### Docker build performance — things to consider

The following list was generated elsewhere without direct reference to the 
current project, so not all items may be applicable, but they are worth 
reviewing when optimizing the Docker build process:

- Add a `.dockerignore` and exclude `.git`, `node_modules`, `dist`, `.venv`, `build`, `docs/_site`, large test/data directories to reduce build context upload.
- Copy dependency metadata first (e.g., `pyproject.toml`, `uv.lock`) and run dependency install before copying the rest of the source to maximize layer cache reuse.
- Split dependency install into its own stage (`dependencies`) and reuse it as the base for other targets; build it once and reference with `--target`/image tag.
- Enable BuildKit and use cache mounts for package caches (pip/uv). Example: `RUN --mount=type=cache,id=pycache,target=/root/.cache/pip uv sync --frozen`.
- Use `docker buildx` with `--cache-to` / `--cache-from` in CI to persist and reuse layer cache across jobs (or push cache to a registry).
- Avoid copying entire repo early (no `COPY . /app` before deps); only copy files needed for install, then `COPY` the rest.
- Combine apt installs and cleanup in a single `RUN` to reduce layers and keep image small: `apt-get update && apt-get install -y ... && rm -rf /var/lib/apt/lists/*`.
- Only install runtime system packages in the final image; keep build-only tooling in an earlier stage and discard it.
- Pin base image (e.g., `python:3.13-slim-bookworm@sha256:...`) to avoid cache misses from upstream image updates.
- Use slim/minimal base images and remove unused packages to shorten install time and image size.
- Avoid running tests or long tasks during image build; run tests in CI using the test stage or separate job after the image is built.
- Use named volumes (not literal `/app/.venv`) to persist venv between restarts, or keep venv in the dependency image and bind-mount source only.
- Provide build-time ARG/ENV flags to skip expensive steps for quick dev builds (e.g., `--build-arg SKIP_DOCS=true`).
- Reduce context size by setting `build.context` to a narrow path if possible instead of the entire repo.
- Use `--target` to build only needed stages during iterative work (e.g., `--target dependencies`).
- Cache package indexes and set HTTP/registry mirrors (CI/config) to speed downloads when allowed by policy.
- In CI, persist Docker daemon build cache between runs (runner-specific) or use remote cache backends.
- Profile the build to find hotspots: measure which RUN steps take the most time and address them first.

### Project-specific Docker optimizations to consider

- The `api-dev` and `demo` images do not need all the documentation for the 
  project. We could exclude `docs/` from those images.
- The `docs` image does in fact require the source code because there is 
  dynamically generated content that leverages docstrings and runs python 
  code as part of the `mkdocs` process.
- none of the current images require the plan, prompts, specs, or notes 
  directories.

